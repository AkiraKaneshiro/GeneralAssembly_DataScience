{
 "metadata": {
  "name": "DE5"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "import pandas as pd\nimport numpy as np\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.cross_validation import train_test_split",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "Note: This is a longer implementation of solution that I left in for future reference."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "df = pd.read_csv('https://raw.githubusercontent.com/TeachingDataScience/data-science-course/forstudentviewing/12_Naive_Bayes/twitter_training/sts_gold_tweet.csv',';')",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "df['percent_capitalized'] = df.tweet.apply(lambda x: sum([float(x[i] == x.upper()[i]) for i in range(len(x))])/len(x))\ndf.head()",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": "/usr/lib/python2.7/dist-packages/pandas/core/config.py:570: DeprecationWarning: height has been deprecated.\n\n  warnings.warn(d.msg, DeprecationWarning)\n/usr/lib/python2.7/dist-packages/pandas/core/common.py:206: DeprecationWarning: numpy boolean negative (the unary `-` operator) is deprecated, use the bitwise_xor (the `^` operator) or the logical_xor function instead.\n  return -res\n/usr/lib/python2.7/dist-packages/pandas/core/config.py:570: DeprecationWarning: height has been deprecated.\n\n  warnings.warn(d.msg, DeprecationWarning)\n/usr/lib/python2.7/dist-packages/pandas/core/common.py:206: DeprecationWarning: numpy boolean negative (the unary `-` operator) is deprecated, use the bitwise_xor (the `^` operator) or the logical_xor function instead.\n  return -res\n/usr/lib/python2.7/dist-packages/pandas/core/config.py:570: DeprecationWarning: height has been deprecated.\n\n  warnings.warn(d.msg, DeprecationWarning)\n/usr/lib/python2.7/dist-packages/pandas/core/common.py:206: DeprecationWarning: numpy boolean negative (the unary `-` operator) is deprecated, use the bitwise_xor (the `^` operator) or the logical_xor function instead.\n  return -res\n"
      },
      {
       "html": "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>polarity</th>\n      <th>tweet</th>\n      <th>percent_capitalized</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td> 1467933112</td>\n      <td> 0</td>\n      <td> the angel is going to miss the athlete this we...</td>\n      <td> 0.192308</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td> 2323395086</td>\n      <td> 0</td>\n      <td> It looks as though Shaq is getting traded to C...</td>\n      <td> 0.325397</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td> 1467968979</td>\n      <td> 0</td>\n      <td>    @clarianne APRIL 9TH ISN'T COMING SOON ENOUGH </td>\n      <td> 0.804348</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td> 1990283756</td>\n      <td> 0</td>\n      <td> drinking a McDonalds coffee and not understand...</td>\n      <td> 0.190000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td> 1988884918</td>\n      <td> 0</td>\n      <td> So dissapointed Taylor Swift doesnt have a Twi...</td>\n      <td> 0.235294</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "output_type": "pyout",
       "prompt_number": 3,
       "text": "           id  polarity                                              tweet  \\\n0  1467933112         0  the angel is going to miss the athlete this we...   \n1  2323395086         0  It looks as though Shaq is getting traded to C...   \n2  1467968979         0     @clarianne APRIL 9TH ISN'T COMING SOON ENOUGH    \n3  1990283756         0  drinking a McDonalds coffee and not understand...   \n4  1988884918         0  So dissapointed Taylor Swift doesnt have a Twi...   \n\n   percent_capitalized  \n0             0.192308  \n1             0.325397  \n2             0.804348  \n3             0.190000  \n4             0.235294  "
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "pol = pd.Series(df['polarity'].values).unique()\npol",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 4,
       "text": "array([0, 4])"
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "Tweets to categorize by polarity"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "tweet1 = \"@DataDAVE thanks for the awesome twitter dataset!!\"\ntweet2 = \"I just don't understand lasso??\"",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "The person the tweet is being sent to in tweet1 is irrelevant, so I'll delete that."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "tweet1 = tweet1[10:]\nprint tweet1",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "thanks for the awesome twitter dataset!!\n"
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "Setting up a count vectorizer and an ngram."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "text = df['tweet'].values\nvectorizer = CountVectorizer(ngram_range=(1,1))\nvectorizer.fit(text)\nx = vectorizer.transform(text)\nx_back = x.toarray()",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": "/usr/local/lib/python2.7/dist-packages/numpy/core/fromnumeric.py:2499: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.\n  VisibleDeprecationWarning)\n"
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "Preparing features"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "X = vectorizer.fit_transform(df.tweet)\nY = df['polarity'].values.astype(np.int)\n\nxtrain, xtest, ytrain, ytest = train_test_split(X, Y)",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "Creating the classifier"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "polarity_vectorizer = vectorizer.fit(df.tweet)\n\n#helper functions\n\n# add parameters to make sure function is robust, xtrain, ytrain, xtest, ytest\ndef accuracy_report(_clf):\n    \n    print \"Accuracy: %0.2f%%\" % (100 * _clf.score(xtest, ytest))\n\n    #Print the accuracy on the test and training dataset\n    training_accuracy = _clf.score(xtrain, ytrain)\n    test_accuracy = _clf.score(xtest, ytest)\n\n    #print \"Accuracy on training data: %0.2f\" % (training_accuracy)\n    #print \"Accuracy on test data: %0.2f\" % (test_accuracy)\n    \n    return test_accuracy\n    \ndef analyze_tweet(testtweet, _clf):\n    print \"\\\"\"  + testtweet + \"\\\" is judged by clasifier to be...\"\n    testtweet = polarity_vectorizer.transform([testtweet])\n\n    if (_clf.predict(testtweet)[0] == 4):\n        print \"...a positive tweet.\"\n    else:\n        print \"...a meh tweet.\"\n    return(_clf.predict(testtweet)[0])",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "print \"MultinomialNB: \\n\"\nclf_mn = MultinomialNB().fit(xtrain, ytrain)\naccuracy_report(clf_mn)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "MultinomialNB: \n\nAccuracy: 84.68%\n"
      },
      {
       "output_type": "pyout",
       "prompt_number": 10,
       "text": "0.8467583497053045"
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "print \"BernoulliNB: \\n\"\nclf_b = BernoulliNB().fit(xtrain, ytrain)\naccuracy_report(clf_b)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "BernoulliNB: \n\nAccuracy: 84.68%\n"
      },
      {
       "output_type": "pyout",
       "prompt_number": 11,
       "text": "0.8467583497053045"
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "print \"Logistic Regression: \\n\"\nclf_lr = LogisticRegression().fit(xtrain, ytrain)\naccuracy_report(clf_lr)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "Logistic Regression: \n\nAccuracy: 84.48%\n"
      },
      {
       "output_type": "pyout",
       "prompt_number": 12,
       "text": "0.84479371316306484"
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "I see that logistic regression works the best. Let's see the results when analyzing each of the two test tweets."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "print \"Tweet 1\"\nprint \"------- \\n\"\n\nprint \"Multinomial Anaylsis: \"\nanalyze_tweet(tweet1, clf_mn)\nprint \"\\n\"\n\nprint \"Bayes Anaylsis: \"\nanalyze_tweet(tweet1, clf_b)\nprint \"\\n\"\n\nprint \"Logistic Regression Anaylsis: \"\nanalyze_tweet(tweet1, clf_lr)\nprint \"\\n\"\n\nprint \"Tweet 2\"\nprint \"-------\\n\"\n\nprint \"Multinomial Anaylsis: \"\nanalyze_tweet(tweet2, clf_mn)\nprint \"\\n\"\n\nprint \"Bayes Anaylsis: \"\nanalyze_tweet(tweet2, clf_b)\nprint \"\\n\"\n\nprint \"Logistic Regression Anaylsis: \"\nanalyze_tweet(tweet2, clf_lr)\nprint \"\\n\"",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "Tweet 1\n------- \n\nMultinomial Anaylsis: \n\"thanks for the awesome twitter dataset!!\" is judged by clasifier to be...\n...a positive tweet.\n\n\nBayes Anaylsis: \n\"thanks for the awesome twitter dataset!!\" is judged by clasifier to be...\n...a positive tweet.\n\n\nLogistic Regression Anaylsis: \n\"thanks for the awesome twitter dataset!!\" is judged by clasifier to be...\n...a positive tweet.\n\n\nTweet 2\n-------\n\nMultinomial Anaylsis: \n\"I just don't understand lasso??\" is judged by clasifier to be...\n...a meh tweet.\n\n\nBayes Anaylsis: \n\"I just don't understand lasso??\" is judged by clasifier to be...\n...a meh tweet.\n\n\nLogistic Regression Anaylsis: \n\"I just don't understand lasso??\" is judged by clasifier to be...\n...a meh tweet.\n\n\n"
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "All three did well. Even thought Multinomial and Bayes analysis are not as good as Logistic regression, they are still good enough to correctly classify the two test tweets."
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "Here is the implementation in a condensed form."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "df2 = pd.read_csv('https://raw.githubusercontent.com/TeachingDataScience/data-science-course/forstudentviewing/12_Naive_Bayes/twitter_training/sts_gold_tweet.csv',';')\n\nvectorizer2 = CountVectorizer(ngram_range=(1,1))\nX2 = vectorizer2.fit_transform(df2.tweet)\nY2 = df2['polarity'].values.astype(np.int)\n\nresults = {}\nmulti = []\nbinom = []\nlog_reg = []\n\n#This is a simple implementation of a 1-Fold\n\nfor i in range(5):\n    \n    xtrain2, xtest2, ytrain2, ytest2 = train_test_split(X2, Y2)\n\n    clf_mn2 = MultinomialNB().fit(xtrain2, ytrain2)\n    clf_b2 = BernoulliNB().fit(xtrain2, ytrain2)\n    clf_lr2 = LogisticRegression().fit(xtrain2, ytrain2)\n\n    multi.append(accuracy_report(clf_mn2))\n    binom.append(accuracy_report(clf_b2))\n    log_reg.append(accuracy_report(clf_lr2))\n    \nresults['Multinomial'] = multi\nresults['Binomial'] = binom\nresults['Logistic'] = log_reg",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "Accuracy: 91.75%\nAccuracy: 92.14%\nAccuracy: 94.89%\nAccuracy: 93.12%\nAccuracy: 91.16%\nAccuracy: 94.11%\nAccuracy: 93.52%"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "\nAccuracy: 92.53%\nAccuracy: 94.70%\nAccuracy: 93.12%\nAccuracy: 91.16%\nAccuracy: 93.91%\nAccuracy: 92.93%"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "\nAccuracy: 90.96%\nAccuracy: 95.68%\n"
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "for key in results:\n    print key + \": \" \n    print results[key]\n    print \"Average: \" + str(sum(results[key])/5)\n    print \"\\n\"",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "Multinomial: \n[0.91355599214145378, 0.92141453831041253, 0.92141453831041253, 0.92927308447937129, 0.92927308447937129]\nAverage: 0.922986247544\n\n\nBinomial: \n[0.90569744597249513, 0.92337917485265231, 0.90569744597249513, 0.91552062868369355, 0.90373280943025536]\nAverage: 0.910805500982\n\n\nLogistic: \n[0.94499017681728881, 0.93909626719056971, 0.94499017681728881, 0.94499017681728881, 0.94499017681728881]\nAverage: 0.943811394892\n\n\n"
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "As before, we see that Logistic regression is the best method to use in this classification. The classification of the two test tweets is just as was done in the first implementation. "
    }
   ],
   "metadata": {}
  }
 ]
}